{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%load_ext tensorboard\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import rc\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "from importlib import reload\n",
    "from pathlib import Path\n",
    "import sklearn\n",
    "import joblib\n",
    "import torch\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "# Set the font to a nicer font\n",
    "rc('text', usetex=True)\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.rcParams[\"font.family\"] = \"serif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metric_from_dict(results, method, metric):\n",
    "    vals = []\n",
    "    for _, metric_keys in results.items():\n",
    "        for candidate_method, metric_map in metric_keys.items():\n",
    "            if method != candidate_method:\n",
    "                continue\n",
    "            for metric_name, val in metric_map.items():\n",
    "                if metric_name == metric:\n",
    "                    vals.append(val)\n",
    "    return vals\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standarized Colors and Markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Hyperparameters\n",
    "clrs = sns.color_palette(\"deep\", 15)\n",
    "MAIN_METHOD = \"MixCEM Final\" #\"Entropy CMCMixCEM\"\n",
    "\n",
    "color_map = {\n",
    "    \"Bayes MLP\": \"black\",\n",
    "    \"Bayes Classifier\": \"black\",\n",
    "    \"MixCEM (ours)\": \"red\",\n",
    "    \"MixCEM (No Calibration)\": \"salmon\",\n",
    "    \"MixCEM (no IntCEM loss)\": \"black\",\n",
    "    \"MixCEM + IntCEM\": \"orange\",\n",
    "    \"MixIntCEM (ours)\": \"orange\",\n",
    "    \"IntCEM\": \"cyan\",\n",
    "    \"Logit Joint CBM\": \"salmon\",\n",
    "    \"Independent CBM\": \"lightgreen\",\n",
    "    \"Sequential CBM\": \"slateblue\",\n",
    "}\n",
    "\n",
    "baselines_to_include = [\n",
    "    \"Joint CBM\",\n",
    "    \"Hybrid-CBM\",\n",
    "    \"CEM\",\n",
    "    # \"Sigmoidal CEM\",\n",
    "    \"IntCEM\",\n",
    "    \"ProbCBM\",\n",
    "    \"Posthoc CBM\",\n",
    "    \"Posthoc Hybrid CBM\",\n",
    "    \"Entropy CMCMixCEM\",\n",
    "    \"Bayes MLP\",\n",
    "    \"Sequential CBM\",\n",
    "    \"Independent CBM\",\n",
    "    \"Logit Joint CBM\",\n",
    "]\n",
    "for idx, baseline in enumerate(baselines_to_include):\n",
    "    if baseline not in color_map:\n",
    "        color_map[baseline] = clrs[idx]\n",
    "\n",
    "markers = {\n",
    "    \"Joint CBM\": '-o',\n",
    "    \"Vanilla CBM\": '-o',\n",
    "    \"Sigmoidal Joint CBM\": '-o',\n",
    "    \"Logit Joint CBM\": '-v',\n",
    "    \"Sequential CBM\": '-^',\n",
    "    \"Independent CBM\": '-2',\n",
    "    \"Hybrid-CBM\": '-v',\n",
    "    \"Hybrid CBM\": '-v',\n",
    "    \"CEM\": '-^',\n",
    "    \"IntCEM\": '-x',\n",
    "    \"ProbCBM\": '-s',\n",
    "    \"Posthoc CBM\": '-p',\n",
    "    \"P-CBM\": '-p',\n",
    "    \"Posthoc Hybrid CBM\": '-1',\n",
    "    \"Hybrid Posthoc CBM\": '-1',\n",
    "    \"Hybrid P-CBM\": '-1',\n",
    "    \"MixCEM (ours)\": '--*',\n",
    "    \"MixCEM (No Calibration)\": ':*',\n",
    "    \"MixCEM (no IntCEM loss)\": \":*\",\n",
    "    \"MixCEM + IntCEM\": \":*\",\n",
    "    \"MixIntCEM (ours)\": \":*\",\n",
    "    \"Bayes MLP\": \":.\",\n",
    "    \"Bayes Classifier\": \":.\",\n",
    "}\n",
    "\n",
    "max_limit = 10\n",
    "\n",
    "select_metric = 'val_acc_y_random_group_level_True_use_prior_False_int_auc'\n",
    "\n",
    "rename_map = {\n",
    "    \"Entropy CMCMixIntCEM\": \"MixIntCEM (ours)\",\n",
    "    \"Entropy CMCMixCEM\": \"MixCEM (ours)\",\n",
    "    \"MixCEM Final\": \"MixCEM (ours)\",\n",
    "    \"MixCEM Final All\": \"MixCEM (ours)\",\n",
    "    \"Entropy CMCMixIntCEM No Calibration\": \"MixIntCEM (No Calibration)\",\n",
    "    \"Entropy CMCMixCEM No Calibration\": \"MixCEM (No Calibration)\",\n",
    "    \"MixCEM Final No Calibration\": \"MixCEM (No Calibration)\",\n",
    "    \"Posthoc Hybrid CBM\": \"Residual P-CBM\",\n",
    "    \"Hybrid Posthoc CBM\": \"Residual P-CBM\",\n",
    "    \"Posthoc CBM\": \"P-CBM\",\n",
    "    \"Bayes MLP\": \"Bayes Classifier\",\n",
    "    \"Joint CBM\": \"Vanilla CBM\",\n",
    "    \"Hybrid-CBM\": \"Hybrid CBM\",\n",
    "}\n",
    "used_rename_map = rename_map\n",
    "show_variance = True\n",
    "ood_suffix = 'OOD_sap_0.1_'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Times Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\texttt{CUB}\n",
      "\\texttt{AwA2}\n",
      "\\texttt{Cifar10}\n",
      "-- Example 1: Basic --\n",
      "Texttable Output:\n",
      "+---------------+--------------------+--------------------+--------------------+\n",
      "|    Method     |    \\texttt{CUB}    |   \\texttt{AwA2}    |  \\texttt{Cifar10}  |\n",
      "+===============+====================+====================+====================+\n",
      "|               | $ \\textcolor{black | $ \\textcolor{black | $ \\textcolor{black |\n",
      "|    ProbCBM    |    }{67.90_{\\pm    |   }{182.38_{\\pm    |   }{1066.27_{\\pm   |\n",
      "|               |      6.54}}$       |      6.09}}$       |      0.00}}$       |\n",
      "+---------------+--------------------+--------------------+--------------------+\n",
      "|               | $ \\textcolor{black | $ \\textcolor{black | $ \\textcolor{black |\n",
      "|      CEM      |    }{30.34_{\\pm    |    }{82.44_{\\pm    |    }{32.37_{\\pm    |\n",
      "|               |      2.87}}$       |      9.38}}$       |      0.52}}$       |\n",
      "+---------------+--------------------+--------------------+--------------------+\n",
      "|               | $ \\textcolor{black | $ \\textcolor{black | $ \\textcolor{black |\n",
      "|    IntCEM     |    }{53.75_{\\pm    |   }{149.96_{\\pm    |    }{93.85_{\\pm    |\n",
      "|               |      8.81}}$       |      8.94}}$       |      1.58}}$       |\n",
      "+---------------+--------------------+--------------------+--------------------+\n",
      "|               | $ \\textcolor{black | $ \\textcolor{black | $ \\textcolor{black |\n",
      "| MixCEM (ours) | }{\\underline{9.92_ |    }{69.36_{\\pm    |    }{21.28_{\\pm    |\n",
      "|               |   {\\pm 0.00}}}$    |      16.59}}$      |      7.30}}$       |\n",
      "+---------------+--------------------+--------------------+--------------------+\n",
      "\n",
      "Latextable Output:\n",
      "\\begin{table}[ht]\n",
      "\t\\caption{Task Accuracy results}\n",
      "\t\\begin{center}\n",
      "\t\t\\begin{tabular}{cccc}\n",
      "\t\t\t\\toprule\n",
      "\t\t\tMethod & \\texttt{CUB} & \\texttt{AwA2} & \\texttt{Cifar10} \\\\\n",
      "\t\t\t\\midrule\n",
      "\t\t\tProbCBM & $ \\textcolor{black}{67.90_{\\pm 6.54}}$ & $ \\textcolor{black}{182.38_{\\pm 6.09}}$ & $ \\textcolor{black}{1066.27_{\\pm 0.00}}$ \\\\\n",
      "\t\t\tCEM & $ \\textcolor{black}{30.34_{\\pm 2.87}}$ & $ \\textcolor{black}{82.44_{\\pm 9.38}}$ & $ \\textcolor{black}{32.37_{\\pm 0.52}}$ \\\\\n",
      "\t\t\tIntCEM & $ \\textcolor{black}{53.75_{\\pm 8.81}}$ & $ \\textcolor{black}{149.96_{\\pm 8.94}}$ & $ \\textcolor{black}{93.85_{\\pm 1.58}}$ \\\\\n",
      "\t\t\tMixCEM (ours) & $ \\textcolor{black}{\\underline{9.92_{\\pm 0.00}}}$ & $ \\textcolor{black}{69.36_{\\pm 16.59}}$ & $ \\textcolor{black}{21.28_{\\pm 7.30}}$ \\\\\n",
      "\t\t\t\\bottomrule\n",
      "\t\t\\end{tabular}\n",
      "\t\\end{center}\n",
      "\t\\label{tab:task_accuracy_summary}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "from texttable import Texttable\n",
    "import latextable\n",
    "from collections import defaultdict\n",
    "\n",
    "results_to_include = [\n",
    "    dict(\n",
    "        path='/anfs/bigdisc/me466/mixcem_results/cub_complete/',\n",
    "        name='\\\\texttt{CUB}',\n",
    "    ),\n",
    "    # dict(\n",
    "    #     path='/anfs/bigdisc/me466/mixcem_results/cub_incomplete/',\n",
    "    #     name='\\\\texttt{CUB-Incomplete}',\n",
    "    #     rename={'Posthoc Hybrid CBM': 'Hybrid Posthoc CBM'},\n",
    "    # ),\n",
    "    dict(\n",
    "        path='/anfs/bigdisc/me466/mixcem_results/awa2_complete/',\n",
    "        name='\\\\texttt{AwA2}',\n",
    "    ),\n",
    "    # dict(\n",
    "    #     path='/anfs/bigdisc/me466/mixcem_results/awa2_incomplete/',\n",
    "    #     name='\\\\texttt{AwA2-Incomplete}',\n",
    "    # ),\n",
    "    dict(\n",
    "        path='/anfs/bigdisc/me466/mixcem_results/cifar10/',\n",
    "        name='\\\\texttt{Cifar10}',\n",
    "    ),\n",
    "    # dict(\n",
    "    #     path='/anfs/bigdisc/me466/mixcem_results/celeba/',\n",
    "    #     name='\\\\texttt{CelebA}',\n",
    "    # ),\n",
    "]\n",
    "\n",
    "for res in results_to_include:\n",
    "    print(res['name'])\n",
    "    res['results'] = joblib.load(os.path.join(res['path'], 'results.joblib'))\n",
    "\n",
    "latex_table = Texttable()\n",
    "baselines_to_include = [\n",
    "    # \"DNN\",\n",
    "    # \"Joint CBM\",\n",
    "    # \"Hybrid-CBM\",\n",
    "    # \"Sigmoidal CEM\",\n",
    "    \"ProbCBM\",\n",
    "    # \"Posthoc CBM\",\n",
    "    # \"Posthoc Hybrid CBM\",\n",
    "    \"CEM\",\n",
    "    \"IntCEM\",\n",
    "    MAIN_METHOD,\n",
    "]\n",
    "num_stds = 2\n",
    "select_metric = 'val_acc_y_random_group_level_True_use_prior_False_int_auc'\n",
    "cols = [\"Method\"] + [x['name'] for x in results_to_include]\n",
    "rows = []\n",
    "metrics_to_include = [('training_time', 'black')]\n",
    "col_results =  [defaultdict(list) for _ in metrics_to_include]\n",
    "best_col_results = [defaultdict(lambda: (float(\"inf\"), None)) for _ in metrics_to_include]\n",
    "\n",
    "for idx, label in enumerate(baselines_to_include):\n",
    "    new_row = []\n",
    "    for col, dataset_results in enumerate(results_to_include):\n",
    "        real_label = dataset_results.get('rename', {}).get(label, label)\n",
    "        used_select_metric = dataset_results.get(\n",
    "            'select_metric',\n",
    "            select_metric,\n",
    "        )\n",
    "        dataset_results['selected_models'] = joblib.load(os.path.join(dataset_results['path'], f'selected_models_{used_select_metric}.joblib'))\n",
    "        selected_models = dataset_results['selected_models']\n",
    "        model_name = selected_models.get(\n",
    "            real_label + \" (Baseline)\",\n",
    "            real_label + \" (Baseline)\",\n",
    "        )\n",
    "        results = dataset_results['results']\n",
    "        metric_vals = []\n",
    "        for metric_idx, (metric, color) in enumerate(metrics_to_include):\n",
    "            metric_val = np.array(get_metric_from_dict(\n",
    "                results,\n",
    "                model_name,\n",
    "                metric,\n",
    "            ))\n",
    "            num_epochs = np.array(get_metric_from_dict(\n",
    "                results,\n",
    "                model_name,\n",
    "                'num_epochs',\n",
    "            ))\n",
    "            metric_val = metric_val / num_epochs\n",
    "            used_name = rename_map.get(label, label)\n",
    "            if len(new_row) == 0:\n",
    "                new_row.append(used_name)\n",
    "            mean = np.mean(metric_val, axis=0)\n",
    "            std = np.std(metric_val, axis=0)\n",
    "            if mean < best_col_results[metric_idx][col][0]:\n",
    "                best_col_results[metric_idx][col] = (mean, std)\n",
    "            col_results[metric_idx][col].append((mean, std))\n",
    "    rows.append(new_row)\n",
    "\n",
    "for idx, label in enumerate(baselines_to_include):\n",
    "    new_row = rows[idx]\n",
    "    for col, dataset_results in enumerate(results_to_include):\n",
    "        entry = '$'\n",
    "        for metric_idx, (metric, color) in enumerate(metrics_to_include):\n",
    "            mean, std = col_results[metric_idx][col][idx]\n",
    "            if metric_idx:\n",
    "                entry += \" \\; / \\;\"\n",
    "            if \"DNN\" in label and metric == \"test_auc_c\":\n",
    "                # Then this is not applicable\n",
    "                entry += \" \\\\textcolor{gray}{\\\\text{N/A \\; \\; \\; \\; \\;}} \"\n",
    "            else:\n",
    "                if mean + num_stds * std <= (best_col_results[metric_idx][col][0] - num_stds * best_col_results[metric_idx][col][1]):\n",
    "                    entry += (f\" \\\\textcolor{{{color}}}{{\\\\underline{{{mean:.2f}_{{\\pm {std:.2f}}}}}}}\")\n",
    "                else:\n",
    "                    entry += (f\" \\\\textcolor{{{color}}}{{{mean:.2f}_{{\\pm {std:.2f}}}}}\")\n",
    "        new_row.append(entry + \"$\")\n",
    "\n",
    "latex_table.set_cols_align([\"c\" for _ in cols])\n",
    "latex_table.set_cols_valign([\"m\" for _ in cols])\n",
    "latex_table.add_rows([cols] + rows)\n",
    "print('-- Example 1: Basic --')\n",
    "print('Texttable Output:')\n",
    "print(latex_table.draw())\n",
    "print('\\nLatextable Output:')\n",
    "print(\n",
    "    latextable.draw_latex(\n",
    "        latex_table,\n",
    "        caption=(\n",
    "            \"Task Accuracy results\"\n",
    "        ),\n",
    "        caption_above=True,\n",
    "        label=\"tab:task_accuracy_summary\",\n",
    "        position=\"ht\",\n",
    "        use_booktabs=True,\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+--------------------+--------------------+\n",
      "|               |   Training Time    |     Epochs to      | Seconds per Epoch  |\n",
      "|               |       (min)        |    Convergence     |                    |\n",
      "+===============+====================+====================+====================+\n",
      "|    IntCEM     |    $ 31.66_{\\pm    |   $ 115.00_{\\pm    |    $ 16.54_{\\pm    |\n",
      "|               |       3.87}$       |      15.00}$       |       0.14}$       |\n",
      "+---------------+--------------------+--------------------+--------------------+\n",
      "| MixCEM (ours) |    $ 32.95_{\\pm    |   $ 160.00_{\\pm    |    $ 12.35_{\\pm    |\n",
      "|               |       1.65}$       |       0.00}$       |       0.62}$       |\n",
      "+---------------+--------------------+--------------------+--------------------+\n",
      "\n",
      "Latextable Output:\n",
      "\\begin{table}[ht]\n",
      "\t\\caption{Training ablation}\n",
      "\t\\begin{center}\n",
      "\t\t\\begin{tabular}{cccc}\n",
      "\t\t\t\\toprule\n",
      "\t\t\t & Training Time (min) & Epochs to Convergence & Seconds per Epoch \\\\\n",
      "\t\t\t\\midrule\n",
      "\t\t\tIntCEM & $ 31.66_{\\pm 3.87}$ & $ 115.00_{\\pm 15.00}$ & $ 16.54_{\\pm 0.14}$ \\\\\n",
      "\t\t\tMixCEM (ours) & $ 32.95_{\\pm 1.65}$ & $ 160.00_{\\pm 0.00}$ & $ 12.35_{\\pm 0.62}$ \\\\\n",
      "\t\t\t\\bottomrule\n",
      "\t\t\\end{tabular}\n",
      "\t\\end{center}\n",
      "\t\\label{tab:training_times}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "from texttable import Texttable\n",
    "import latextable\n",
    "from collections import defaultdict\n",
    "\n",
    "dataset_results = dict(\n",
    "    path='/anfs/bigdisc/me466/mixcem_results/cub_incomplete_smaller_ablation/',\n",
    "    name='\\\\texttt{CUB-Incomplete}',\n",
    ")\n",
    "select_metric = 'val_acc_y_random_group_level_True_use_prior_False_int_auc'\n",
    "dataset_results['results'] = joblib.load(os.path.join(dataset_results['path'], 'results.joblib'))\n",
    "dataset_results['selected_models'] = joblib.load(os.path.join(dataset_results['path'], f'selected_models_{select_metric}.joblib'))\n",
    "\n",
    "latex_table = Texttable()\n",
    "baselines_to_include = [\n",
    "    \"Base IntCEM\",\n",
    "    \"Base MixCEM\"\n",
    "]\n",
    "used_rename_map = {\n",
    "    \"Base IntCEM\": \"IntCEM\",\n",
    "    \"Base MixCEM\": \"MixCEM (ours)\",\n",
    "}\n",
    "num_stds = 2\n",
    "metrics_to_include = [('training_time', 'Training Time (min)', None, 'min'), ('num_epochs', 'Epochs to Convergence', None, 'min'), ('sec_per_epoch', 'Seconds per Epoch', None, 'min')]\n",
    "cols = [\"\"] + [name for (_, name, _, _) in metrics_to_include]\n",
    "rows = []\n",
    "col_results =  defaultdict(list)\n",
    "best_col_results = defaultdict(lambda: (float(\"inf\"), None))\n",
    "\n",
    "for idx, label in enumerate(baselines_to_include):\n",
    "    new_row = []\n",
    "    selected_models = dataset_results['selected_models']\n",
    "    model_name = selected_models.get(\n",
    "        label,\n",
    "        label,\n",
    "    )\n",
    "    results = dataset_results['results']\n",
    "    metric_vals = []\n",
    "    for col, (metric, col_name, color, mode) in enumerate(metrics_to_include):\n",
    "        if metric == 'sec_per_epoch':\n",
    "            metric_val = np.array(get_metric_from_dict(\n",
    "                results,\n",
    "                model_name,\n",
    "                'training_time',\n",
    "            ))\n",
    "            num_epochs = np.array(get_metric_from_dict(\n",
    "                results,\n",
    "                model_name,\n",
    "                'num_epochs',\n",
    "            ))\n",
    "            metric_val = metric_val / num_epochs\n",
    "        elif metric == 'training_time':\n",
    "            metric_val = np.array(get_metric_from_dict(\n",
    "                results,\n",
    "                model_name,\n",
    "                metric,\n",
    "            )) / 60\n",
    "        else:\n",
    "            metric_val = np.array(get_metric_from_dict(\n",
    "                results,\n",
    "                model_name,\n",
    "                metric,\n",
    "            ))\n",
    "        used_name = used_rename_map.get(label, label)\n",
    "        if len(new_row) == 0:\n",
    "            new_row.append(used_name)\n",
    "        mean = np.mean(metric_val, axis=0)\n",
    "        std = np.std(metric_val, axis=0)\n",
    "        if mode == 'min':\n",
    "            if mean < best_col_results[col][0]:\n",
    "                best_col_results[col] = (mean, std)\n",
    "        else:\n",
    "            if mean > best_col_results[col][0]:\n",
    "                best_col_results[col] = (mean, std)\n",
    "        col_results[col].append((mean, std))\n",
    "    rows.append(new_row)\n",
    "\n",
    "for idx, label in enumerate(baselines_to_include):\n",
    "    new_row = rows[idx]\n",
    "    for col, (metric, col_name, color, mode) in enumerate(metrics_to_include):\n",
    "        entry = '$'\n",
    "        mean, std = col_results[col][idx]\n",
    "        if mode == 'max':\n",
    "            if mean + num_stds * std >= (best_col_results[col][0] - num_stds * best_col_results[col][1]):\n",
    "                if color is not None:\n",
    "                    entry += (f\" \\\\textcolor{{{color}}}{{\\\\underline{{{mean:.2f}_{{\\pm {std:.2f}}}}}}}\")\n",
    "                else:\n",
    "                    entry += (f\" \\\\underline{{{mean:.2f}_{{\\pm {std:.2f}}}}}\")\n",
    "            else:\n",
    "                if color is not None:\n",
    "                    entry += (f\" \\\\textcolor{{{color}}}{{{mean:.2f}_{{\\pm {std:.2f}}}}}\")\n",
    "                else:\n",
    "                    entry += (f\" {mean:.2f}_{{\\pm {std:.2f}}}\")\n",
    "        else:\n",
    "            if mean + num_stds * std <= (best_col_results[col][0] - num_stds * best_col_results[col][1]):\n",
    "                if color is not None:\n",
    "                    entry += (f\" \\\\textcolor{{{color}}}{{\\\\underline{{{mean:.2f}_{{\\pm {std:.2f}}}}}}}\")\n",
    "                else:\n",
    "                    entry += (f\" \\\\underline{{{mean:.2f}_{{\\pm {std:.2f}}}}}\")\n",
    "            else:\n",
    "                if color is not None:\n",
    "                    entry += (f\" \\\\textcolor{{{color}}}{{{mean:.2f}_{{\\pm {std:.2f}}}}}\")\n",
    "                else:\n",
    "                    entry += (f\" {mean:.2f}_{{\\pm {std:.2f}}}\")\n",
    "        new_row.append(entry + \"$\")\n",
    "\n",
    "latex_table.set_cols_align([\"c\" for _ in cols])\n",
    "latex_table.set_cols_valign([\"m\" for _ in cols])\n",
    "latex_table.add_rows([cols] + rows)\n",
    "print(latex_table.draw())\n",
    "print('\\nLatextable Output:')\n",
    "print(\n",
    "    latextable.draw_latex(\n",
    "        latex_table,\n",
    "        caption=(\n",
    "            \"Training ablation\"\n",
    "        ),\n",
    "        caption_above=True,\n",
    "        label=\"tab:training_times\",\n",
    "        position=\"ht\",\n",
    "        use_booktabs=True,\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {0: (-inf, None), 1: (-inf, None), 2: (-inf, None)})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_col_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
