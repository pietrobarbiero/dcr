trials: 3
model_selection_trials: 1

results_dir: /anfs/bigdisc/me466/mixcem_results/color_mnist_svhn_incomplete_rebuttal/

model_selection_groups:
  - ["^(CBM_Sigmoid).*$", "Joint CBM (Baseline)"]
  - ["^(CBM_Logit).*$", "Logit CBM (Baseline)"]
  - ["^(Hybrid-CBM_).*$", "Hybrid-CBM (Baseline)"]
  - ["^(CEM).*$", "CEM (Baseline)"]
  - ["^(IntCEM_).*$", "IntCEM (Baseline)"]
  - ["^(DNN_).*$", "DNN (Baseline)"]
  - ["^(ProbCBM).*$", "ProbCBM (Baseline)"]
  - ["^(PCBM).*$", "Posthoc CBM (Baseline)"]
  - ["^(HybridPCBM).*$", "Hybrid Posthoc CBM (Baseline)"]
  - [".*(MixCEM_Final_t_).*(emc_50_).*$", "MixCEM Final All Sample (Baseline)"]


model_selection_metrics:
  - val_auc_y_random_group_level_True_use_prior_False_int_auc
  - val_auc

shared_params:
  # Intervention Parameters
  intervention_config:
    competence_levels: [1]
    intervention_freq: 1
    intervention_batch_size: 2048
    use_auc: True
    val_intervention_policies:
      - policy: "random"
        group_level: True
        use_prior: False
    intervention_policies:
      - policy: "random"
        group_level: True
        use_prior: False

  # Evaluation configuration
  eval_config:
    additional_test_sets:
      # - name: "OOD_SVHN_10"
      #   update_previous: True
      #   dataset_config:
      #     svhn_percentage: 0.10
      # - name: "OOD_SVHN_25"
      #   update_previous: True
      #   dataset_config:
      #     svhn_percentage: 0.25
      - name: "OOD_SVHN_50"
        update_previous: True
        dataset_config:
          svhn_percentage: 0.5
      - name: "OOD_SVHN_100"
        update_previous: True
        dataset_config:
          svhn_percentage: 1


  # Representation metrics
  # Change to False if you want representation metrics to be included in the
  # evaluation (may significantly increase experiment times)
  skip_repr_evaluation: True
  top_k_accuracy: null
  save_model: True
  emb_size: 8
  verbose: True
  extra_dims: 0
  concept_loss_weight: [10, 1]
  learning_rate: 0.01
  c_extractor_arch: color_mnist_extractor

  optimizer: adam
  max_epochs: 150
  bool: False
  early_stopping_monitor: val_loss
  early_stopping_mode: min
  early_stopping_delta: 0.0001
  patience: 15
  momentum: 0.9
  sigmoidal_prob: False
  training_intervention_prob: 0.25
  c2y_layers: []
  use_task_class_weights: True
  weight_loss: False
  check_val_every_n_epoch: 5
  grid_variables:
    - concept_loss_weight
  grid_search_mode: exhaustive

   # Dataset Configuration
  dataset_config:
    dataset: color_mnist_add
    root_dir: data/
    num_workers: 8
    batch_size: 2048
    num_operands: 5 #10 #10
    selected_digits: [0, 1, 2, 3, 4] #[0, 1, 2, 3]
    count_labels: False
    # range_labels: null #[5, 10, 15, 20, 25, 30, 35, 40] #[5, 10, 15, 20, 25]
    range_labels: [10] #[20] #[5, 10, 15, 20, 25]
    low_noise_level: 0 #1
    noise_level: 0 #0.25
    test_low_noise_level: 0 #1
    test_noise_level: 0 #0.25
    train_dataset_size: 10000 #20000
    test_dataset_size: 5000
    sampling_percent: 0.8
    sampling_groups: True
    test_subsampling: 1
    weight_loss: False

    # # CHANGES!!!!!!!!!!!!!!!
    colors: ["gray"]
    concat_dim: c

    color_by_label: False
    # colors: ["random_1", "random_2", "random_3", "random_4", "random_5", "random_6", "random_7", "random_8", "random_9", "random_10"]
    # digit_color_distribution:
    #   0: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
    #   1: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
    #   2: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
    #   3: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
    #   4: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
    #   5: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
    #   6: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
    #   7: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
    #   8: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
    #   9: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]

    # test_digit_color_distribution:
    #   0: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
    #   1: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
    #   2: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
    #   3: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
    #   4: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
    #   5: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
    #   6: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
    #   7: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
    #   8: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
    #   9: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]



runs:
  - architecture: 'ConceptEmbeddingModel'
    run_name: "CEM_emb_size_{emb_size}_cwl_{concept_loss_weight}"
    training_intervention_prob: 0.25
    emb_size: [16]
    embedding_activation: "leakyrelu"
    sigmoidal_prob: True
    grid_variables:
      - concept_loss_weight
      - emb_size
    grid_search_mode: exhaustive

  - architecture: 'MCIntCEM'
    run_name: "MixCEM_Final_t_{temperature}_r_{all_intervened_loss_weight}_{pooling_mode}_{uncerainty_threshold_percentile}_{global_epochs}_mpc_{mixed_probs_coeff}_tmc_{montecarlo_train_tries}_emc_{montecarlo_test_tries}_cwc_{class_wise_temperature}_ce_{calibration_epochs}_g_ood_{ood_dropout_prob}_emb_{emb_size}_{finetune_with_val}_tip_{training_intervention_prob}_itd_{intervention_task_discount}_iw_{intervention_weight}_cwl_{concept_loss_weight}"
    load_path_name: "MixCEM_Final_t_{temperature}_r_{all_intervened_loss_weight}_{pooling_mode}_None_{global_epochs}_mpc_{mixed_probs_coeff}_tmc_1_emc_0_cwc_{class_wise_temperature}_ce_0_g_ood_{ood_dropout_prob}_emb_{emb_size}_True_tip_{training_intervention_prob}_itd_{intervention_task_discount}_iw_{intervention_weight}_cwl_{concept_loss_weight}"
    global_model_path: "g_MixCEM_Final_t_{temperature}_r_{all_intervened_loss_weight}_{pooling_mode}_{uncerainty_threshold_percentile}_{global_epochs}_mpc_{mixed_probs_coeff}_tmc_1_emc_0_cwc_{class_wise_temperature}_ce_{calibration_epochs}_g_ood_{ood_dropout_prob}_emb_{emb_size}_{finetune_with_val}_tip_{training_intervention_prob}_itd_{intervention_task_discount}_iw_{intervention_weight}_cwl_{concept_loss_weight}"

    emb_size: [16]
    concept_loss_weight: [10, 1]
    shared_emb_generator: True
    montecarlo_train_tries: [1]
    montecarlo_test_tries: [50]
    ood_dropout_prob: [0.5, 0.1, 0.9] #, 0.5, 0.1]
    pooling_mode: ['concat']
    calibration_epochs: [30]
    finetune_with_val: [True]
    learnable_temps: False
    class_wise_temperature: False
    global_epochs: [0]
    global_mixed_probs_coeff: 0
    freeze_global_embeddings: False
    max_epochs: 150
    uncerainty_threshold_percentile: [null]
    inference_threshold: False
    mixed_probs_coeff: [1]
    all_intervened_loss_weight: [10, 1, 0.1] #[1]
    calibrate_concept_probs: True
    dynamic_confidence_scaling: True
    temperature: [1]
    scale_fn: entropy

    ###############################################################################################

    # IntCEM stuff
    embedding_activation: null
    training_intervention_prob: [0.25]
    intervention_task_discount: [1]
    use_concept_groups: True
    int_model_use_bn: False
    int_model_layers: []
    max_horizon: 1
    horizon_rate: 1
    intervention_weight: [0]
    grid_variables:
      - training_intervention_prob
      - intervention_task_discount
      - ood_dropout_prob
      - emb_size
      - finetune_with_val
      - concept_loss_weight
      - pooling_mode
      - intervention_weight
      - global_epochs
      - montecarlo_train_tries
      - mixed_probs_coeff
      - all_intervened_loss_weight
      - temperature
      - calibration_epochs
      - uncerainty_threshold_percentile
      - montecarlo_test_tries
    grid_search_mode: exhaustive

  # ProbCBM_cwl_class_hidden_dim_128_hidden_dim_16_n_samples_inference_50_max_concept_epochs_70_max_task_epochs_75
  - architecture: 'ProbabilisticConceptBottleneckModel'
    run_name: "ProbCBM_cwl_class_hidden_dim_{class_hidden_dim}_hidden_dim_{hidden_dim}_n_samples_inference_{n_samples_inference}_max_concept_epochs_{max_concept_epochs}_max_task_epochs_{max_task_epochs}"
    n_samples_inference: 50
    use_neg_concept: True
    pred_class: True
    init_negative_scale: 5
    init_shift: 5
    pretrained: True
    hidden_dim: [32, 16]
    class_hidden_dim: [128, 64]
    intervention_prob: 0.5
    # gradient_clip_val: 2.0
    max_concept_epochs: 150 #70
    warmup_epochs: 30 #5
    max_task_epochs: 150 #75
    vib_beta: 0.00005
    concept_loss_weight: 1
    # learning_rate: 0.001
    lr_ratio: 10
    weight_decay: 0
    weight_loss: False
    # optimizer: adam
    grid_variables:
      - class_hidden_dim
      - hidden_dim
    grid_search_mode: exhaustive
    dataset_config:
      dataset: color_mnist_add
      root_dir: data/
      num_workers: 8
      batch_size: 512 # 2048 CHANGE!!!!!!!!
      num_operands: 5
      selected_digits: [0, 1, 2, 3, 4]
      count_labels: False
      range_labels: [10]
      low_noise_level: 0
      noise_level: 0
      test_low_noise_level: 0
      test_noise_level: 0
      train_dataset_size: 10000
      test_dataset_size: 5000
      sampling_percent: 0.8
      sampling_groups: True
      test_subsampling: 1
      weight_loss: False

      # # CHANGES!!!!!!!!!!!!!!!
      colors: ["gray"]
      concat_dim: c

      color_by_label: False

  - architecture: "IntAwareConceptEmbeddingModel"
    run_name: "IntCEM_emb_size_{emb_size}_intervention_weight_{intervention_weight}_intervention_task_discount_{intervention_task_discount}_cwl_{concept_loss_weight}"
    training_intervention_prob: 0.25
    intervention_weight: [0.1, 1]
    intervention_task_discount: [1.1, 1.5]
    use_concept_groups: True
    int_model_use_bn: True
    int_model_layers: [128, 128, 64, 64]
    embedding_activation: "leakyrelu"
    max_horizon: 6
    horizon_rate: 1.005
    gradient_clip_val: 100
    emb_size: [16]
    concept_loss_weight: [1]
    grid_variables:
        - concept_loss_weight
        - intervention_task_discount
        - intervention_weight
        - emb_size
    grid_search_mode: exhaustive

  # DNN_extra_dims_200
  - architecture: 'ConceptBottleneckModel'
    run_name: "DNN_extra_dims_{extra_dims}"
    extra_dims: [200]
    training_intervention_prob: 0
    embedding_activation: "leakyrelu"
    sigmoidal_prob: True
    concept_loss_weight: 0
    grid_variables:
      - extra_dims
    grid_search_mode: exhaustive

  - architecture: 'ConceptBottleneckModel'
    run_name: "Hybrid-CBM_Sigmoid_extra_dims_{extra_dims}_cwl_{concept_loss_weight}"
    extra_dims: [50, 200]
    training_intervention_prob: 0
    embedding_activation: "leakyrelu"
    sigmoidal_prob: True
    grid_variables:
      - concept_loss_weight
      - extra_dims
    grid_search_mode: exhaustive

  - architecture: 'ConceptBottleneckModel'
    run_name: "CBM_Sigmoid_cwl_{concept_loss_weight}"
    training_intervention_prob: 0
    embedding_activation: "leakyrelu"
    bool: False
    extra_dims: 0
    sigmoidal_extra_capacity: False
    sigmoidal_prob: True

  # - architecture: 'ConceptBottleneckModel'
  #   run_name: "CBM_Logit_cwl_{concept_loss_weight}"
  #   embedding_activation: "leakyrelu"
  #   bool: False
  #   extra_dims: 0
  #   sigmoidal_extra_capacity: False
  #   sigmoidal_prob: False

  # - architecture: 'SequentialConceptBottleneckModel'
  #   run_name: "CBM_Seq"
  #   concept_loss_weight: [1]
  #   embedding_activation: "leakyrelu"
  #   bool: False
  #   extra_dims: 0
  #   sigmoidal_extra_capacity: False
  #   sigmoidal_prob: True

  # - architecture: 'IndependentConceptBottleneckModel'
  #   run_name: "CBM_Ind"
  #   concept_loss_weight: [1]
  #   embedding_activation: "leakyrelu"
  #   bool: False
  #   extra_dims: 0
  #   sigmoidal_extra_capacity: False
  #   sigmoidal_prob: True

  - architecture: 'ConceptToLabelModel'
    run_name: "ConceptToLabelModel"
    c2y_layers: [128, 64, 32]
    grid_variables: []
    max_epochs: 75
    feature_drop_out: 0.25


  # PCBM_reg_1e-06_l1_0.99_penalty_1
  - architecture: 'PosthocConceptBottleneckModel'
    run_name: "PCBM_reg_{reg_strength}_l1_{l1_ratio}_penalty_{svd_penalty}"
    residual: False
    reg_strength: [0.000001, 0.001, 0.1]
    l1_ratio: [0.99]
    freeze_pretrained_model: True
    freeze_concept_embeddings: True
    emb_size: null

    svd_penalty: [1]
    active_top_percentile: 95
    active_bottom_percentile: 5
    blackbox_model_config:
      name: color_mnist_extractor
      out_activation: sigmoid
      output_dim: 1
    blackbox_training_epochs: 150
    max_residual_epochs: 150
    max_epochs: 150
    blackbox_path: 'PCBM_BlackBox_Model_{blackbox_model_config[name]}_fold_{split}'

    grid_variables:
      - reg_strength
      - l1_ratio
      - svd_penalty
    grid_search_mode: exhaustive

  # HybridPCBM_reg_0.1_l1_0.99_penalty_1
  - architecture: 'PosthocConceptBottleneckModel'
    run_name: "HybridPCBM_reg_{reg_strength}_l1_{l1_ratio}_penalty_{svd_penalty}"
    residual: True  # TURN ON THE RESIDUAL MODEL!
    reg_strength: [0.000001, 0.001, 0.1]
    l1_ratio: [0.99]
    freeze_pretrained_model: True
    freeze_concept_embeddings: True
    emb_size: null

    svd_penalty: [1]
    blackbox_model_config:
      name: color_mnist_extractor
      out_activation: sigmoid
      output_dim: 1
    blackbox_training_epochs: 150
    max_residual_epochs: 150
    max_epochs: 150
    blackbox_path: 'PCBM_BlackBox_Model_{blackbox_model_config[name]}_fold_{split}'

    grid_variables:
      - reg_strength
      - l1_ratio
      - svd_penalty
    grid_search_mode: exhaustive