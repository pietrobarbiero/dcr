trials: 3
results_dir: /anfs/bigdisc/me466/mixcem_results/waterbirds_species/

model_selection_groups:
  - ["^(CBM_Sigmoid_Baseline_).*$", "Joint CBM (Baseline)"]
  - ["^(Hybrid-CBM_).*(_Baseline_).*$", "Hybrid-CBM (Baseline)"]
  - ["^(CEM_Baseline_).*$", "CEM (Baseline)"]
  - ["^(DNN_).*$", "DNN (Baseline)"]
  - ["^(IntCEM_).*(_Baseline).*$", "IntCEM (Baseline)"]
  - ["^(MixCEM_).*(_Baseline).*$", "MixCEM (Baseline)"]


model_selection_metrics:
  - val_acc_y_random_group_level_True_use_prior_False_int_auc

shared_params:
  # Dataset Configuration
  dataset_config:
    dataset: "waterbirds"
    num_workers: 8
    batch_size: 25
    n_classes: 1

    # DATASET VARIABLES
    root_dir: /anfs/bigdisc/me466/waterbirds
    cub_root_dir: /homes/me466/data/CUB200/
    use_attributes: False
    use_bird_species: True
    augment_data: False
    sampling_percent: 1
    sampling_groups: True
    test_subsampling: 1
    weight_loss: True
    val_subsample: 0.2

  # Intervention Parameters
  intervention_config:
    competence_levels: [1]
    intervention_freq: 25
    intervention_batch_size: 512
    val_intervention_policies:
      - policy: "random"
        group_level: True
        use_prior: False
    intervention_policies:
      - policy: "random"
        group_level: True
        use_prior: False

  # Representation metrics
  # Change to False if you want representation metrics to be included in the
  # evaluation (may significantly increase experiment times)
  skip_repr_evaluation: True

  max_epochs: 150
  top_k_accuracy: null
  save_model: True
  patience: 15
  emb_size: 16
  extra_dims: 0
  concept_loss_weight: [5]
  learning_rate: 0.01
  weight_decay: 0.000004
  weight_loss: True
  c_extractor_arch: resnet18
  optimizer: sgd
  bool: False
  early_stopping_monitor: val_loss
  early_stopping_mode: min
  early_stopping_delta: 0.0
  momentum: 0.9
  sigmoidal_prob: False
  training_intervention_prob: 0.25
  grid_variables:
    - concept_loss_weight
  grid_search_mode: exhaustive

  # Evaluation configuration
  eval_config:
    additional_test_sets:
      - name: "OOD"
        update_previous: True
        dataset_config:
          test_transformation_config:
            name: random_noise
            low_noise_level: 1
            noise_level: 0.5
      # - name: "OOD_heavy"
      #   update_previous: True
      #   dataset_config:
      #     test_transformation_config:
      #       name: random_noise
      #       low_noise_level: 1
      #       noise_level: 0.75
      # - name: "OOD_heavier"
      #   update_previous: True
      #   dataset_config:
      #     test_transformation_config:
      #       name: random_noise
      #       low_noise_level: 1
      #       noise_level: 0.95


runs:
  - architecture: 'ConceptBottleneckModel'
    run_name: "DNN_extra_dims_{extra_dims}"
    extra_dims: [0, 100]
    embedding_activation: "leakyrelu"
    sigmoidal_prob: True
    concept_loss_weight: 0
    grid_variables:
      - extra_dims
    grid_search_mode: exhaustive

  - architecture: 'ConceptBottleneckModel'
    run_name: "CBM_Sigmoid_Baseline_cwl_{concept_loss_weight}"
    training_intervention_prob: 0.25
    embedding_activation: "leakyrelu"
    bool: False
    extra_dims: 0
    sigmoidal_extra_capacity: False
    sigmoidal_prob: True
    concept_loss_weight: [0.1, 1, 10]
    grid_variables:
      - concept_loss_weight
    grid_search_mode: exhaustive

  - architecture: 'ConceptBottleneckModel'
    run_name: "Hybrid-CBM_Sigmoid_extra_dims_{extra_dims}_Baseline_cwl_{concept_loss_weight}"
    extra_dims: [50, 100]
    training_intervention_prob: 0
    embedding_activation: "leakyrelu"
    sigmoidal_prob: True
    concept_loss_weight: [0.1, 1, 10]
    grid_variables:
      - concept_loss_weight
      - extra_dims
    grid_search_mode: exhaustive

  - architecture: 'ConceptBottleneckModel'
    run_name: "CBM_Logit_Baseline_cwl_{concept_loss_weight}"
    embedding_activation: "leakyrelu"
    bool: False
    extra_dims: 0
    sigmoidal_extra_capacity: False
    sigmoidal_prob: False
    concept_loss_weight: [0.1, 1, 10]
    grid_variables:
      - concept_loss_weight
    grid_search_mode: exhaustive

  - architecture: 'ProbabilisticConceptBottleneckModel'
    run_name: "ProbCBM_class_hidden_dim_{class_hidden_dim}_hidden_dim_{hidden_dim}_cwl_{concept_loss_weight}"
    n_samples_inference: 50
    use_neg_concept: True
    pred_class: True
    init_negative_scale: 5
    init_shift: 5
    pretrained: True
    hidden_dim: [8] #, 32]
    class_hidden_dim: [4] #32, 64] #128
    intervention_prob: 0.5
    gradient_clip_val: 2.0
    max_concept_epochs: 50
    warmup_epochs: 5
    max_task_epochs: 20
    vib_beta: 0.00005
    concept_loss_weight: [1]
    learning_rate: 0.001
    lr_ratio: 10
    weight_decay: 0
    weight_loss: False
    optimizer: adam
    grid_variables:
      - concept_loss_weight
      - class_hidden_dim
      - hidden_dim
    grid_search_mode: exhaustive
    # Changing the dataset's batch size cause otherwise memory struggles!
    dataset_config:
      dataset: "waterbirds"
      num_workers: 8
      batch_size: 64 #256
      n_classes: 1

      # DATASET VARIABLES
      root_dir: /anfs/bigdisc/me466/waterbirds
      cub_root_dir: /homes/me466/data/CUB200/
      use_attributes: False
      use_bird_species: True
      augment_data: False
      sampling_percent: 1
      sampling_groups: True
      test_subsampling: 1
      weight_loss: True
      val_subsample: 0.2

  - architecture: 'ConceptEmbeddingModel'
    run_name: "CEM_Baseline_emb_size_{emb_size}_cwl_{concept_loss_weight}"
    sigmoidal_prob: True
    emb_size: [16, 8]
    training_intervention_prob: 0.25
    embedding_activation: "leakyrelu"
    concept_loss_weight: [0.1, 1, 10]
    grid_variables:
      - concept_loss_weight
      - emb_size
    grid_search_mode: exhaustive


  - architecture: "IntAwareConceptEmbeddingModel"
    run_name: "IntCEM_intervention_weight_{intervention_weight}_intervention_task_discount_{intervention_task_discount}_Baseline_cwl_{concept_loss_weight}"
    training_intervention_prob: 0.25
    intervention_weight: [0.1, 1, 5]
    intervention_task_discount: [1.1, 1.5]
    use_concept_groups: True
    int_model_use_bn: True
    int_model_layers: [128, 128, 64, 64]
    embedding_activation: "leakyrelu"
    max_horizon: 6
    horizon_rate: 1.005
    gradient_clip_val: 100
    concept_loss_weight: [0.1, 1, 10]
    grid_variables:
        - concept_loss_weight
        - intervention_task_discount
        - intervention_weight
    grid_search_mode: exhaustive

  - architecture: 'MixingConceptEmbeddingModel'
    run_name: "MixCEM_n_extra_{n_discovered_concepts}_entr_{discovered_probs_entropy}_dis_{intervention_task_discount}_ip_{training_intervention_prob}_dip_{dyn_training_intervention_prob}_cl_{contrastive_loss_weight}_mix_{mix_ground_truth_embs}_shared_{shared_emb_generator}_emb_size_{emb_size}_ml_{intermediate_task_concept_loss}_Baseline_cwl_{concept_loss_weight}"
    training_intervention_prob: [[0.25, 0.5, 0.75, 1]]
    emb_size: [128, 32, 16]
    embedding_activation: null
    n_discovered_concepts: [0, 25]
    concept_loss_weight: [0.1, 1, 10]
    contrastive_loss_weight: [0]
    mix_ground_truth_embs: True
    shared_emb_generator: [True]
    normalize_embs: False
    sample_probs: False
    cond_discovery: False
    intermediate_task_concept_loss: [0]
    task_concept_loss: 1
    intervention_task_discount: [1.01, 1.05] #, 1.5]
    discovered_probs_entropy: 0
    dyn_training_intervention_prob: [0.1] #, 0.25] # UNCOMMENT ME!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
    grid_variables:
      - concept_loss_weight
      - n_discovered_concepts
      - contrastive_loss_weight
      - shared_emb_generator
      - emb_size
      - intermediate_task_concept_loss
      - intervention_task_discount
      - training_intervention_prob
      - dyn_training_intervention_prob
    grid_search_mode: exhaustive