{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%load_ext tensorboard\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import rc\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "from importlib import reload\n",
    "from pathlib import Path\n",
    "import sklearn\n",
    "import joblib\n",
    "import torch\n",
    "import pandas as pd\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "## Global Variables Defining Experiment Flow\n",
    "################################################################################\n",
    "\n",
    "GPU = 1\n",
    "NUM_WORKERS = 8\n",
    "rc('text', usetex=False)\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.rcParams[\"font.family\"] = \"serif\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "import cem.data.CUB200.cub_loader as cub_data_module\n",
    "result_dir = \"results/cub_interventions/\"\n",
    "with open(os.path.join(result_dir, \"experiment_2023_05_13_23_50_config.yaml\"), \"r\") as f:\n",
    "    experiment_config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "experiment_config['shared_params']['batch_size'] = 512\n",
    "experiment_config['shared_params']['num_workers'] = 4\n",
    "train_dl, val_dl, test_dl, imbalance, (n_concepts, n_tasks, concept_map) = \\\n",
    "    cub_data_module.generate_data(\n",
    "        config=experiment_config['shared_params'],\n",
    "        seed=42,\n",
    "        output_dataset_vars=True,\n",
    "        root_dir=experiment_config.get('root_dir', None),\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 0\n",
    "intcem_model_path = os.path.join(\n",
    "    result_dir,\n",
    "    f\"IntAwareConceptEmbeddingModelRetry_intervention_weight_5_horizon_rate_1.005_intervention_discount_1_task_discount_1.1_resnet34_fold_{split + 1}.pt\",\n",
    ")\n",
    "intcem_model_config = joblib.load(\n",
    "    intcem_model_path.replace(\".pt\", \"_experiment_config.joblib\"),\n",
    ")\n",
    "\n",
    "cem_model_path = os.path.join(\n",
    "    result_dir,\n",
    "    f\"ConceptEmbeddingModel_resnet34_fold_{split + 1}.pt\"\n",
    ")\n",
    "cem_model_config = joblib.load(\n",
    "    cem_model_path.replace(\".pt\", \"_experiment_config.joblib\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cem.train.training import load_trained_model\n",
    "from cem.interventions.random import IndependentRandomMaskIntPolicy\n",
    "from cem.interventions.global_policies import ConstantMaskPolicy\n",
    "\n",
    "intcem = load_trained_model(\n",
    "    config=intcem_model_config,\n",
    "    n_tasks=n_tasks,\n",
    "    result_dir=result_dir,\n",
    "    n_concepts=n_concepts,\n",
    "    split=split,\n",
    "    imbalance=imbalance,\n",
    "    task_class_weights=None,\n",
    "    train_dl=train_dl,\n",
    "    sequential=False,\n",
    "    logger=False,\n",
    "    independent=False,\n",
    "    gpu=int(torch.cuda.is_available()),\n",
    "    output_latent=True,\n",
    "    output_interventions=True,\n",
    "    enable_checkpointing=False,\n",
    ")\n",
    "\n",
    "cem = load_trained_model(\n",
    "    config=intcem_model_config,\n",
    "    n_tasks=n_tasks,\n",
    "    result_dir=result_dir,\n",
    "    n_concepts=n_concepts,\n",
    "    split=split,\n",
    "    imbalance=imbalance,\n",
    "    task_class_weights=None,\n",
    "    train_dl=train_dl,\n",
    "    sequential=False,\n",
    "    logger=False,\n",
    "    independent=False,\n",
    "    gpu=int(torch.cuda.is_available()),\n",
    "    intervention_policy=None,\n",
    "    output_latent=True,\n",
    "    output_interventions=True,\n",
    "    enable_checkpointing=False,\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Latent Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concepts_from_competencies(c, competencies):\n",
    "    correct_interventions = np.random.binomial(\n",
    "        n=1,\n",
    "        p=competencies,\n",
    "        size=c.shape,\n",
    "    )\n",
    "    return (\n",
    "        c * correct_interventions + (1 - c) * (1 - correct_interventions)\n",
    "    ).type(torch.FloatTensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2228459/843792930.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m )\n\u001b[0;32m---> 16\u001b[0;31m test_batch_results = trainer.predict(\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mintcem\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mtest_dl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, dataloaders, datamodule, return_predictions, ckpt_path)\u001b[0m\n\u001b[1;32m    991\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mdictionaries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0mprovided\u001b[0m \u001b[0mdataloader\u001b[0m \u001b[0mcontaining\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mrespective\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m         \"\"\"\n\u001b[0;32m--> 993\u001b[0;31m         return self._call_and_handle_interrupt(\n\u001b[0m\u001b[1;32m    994\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m         )\n",
      "\u001b[0;32m~/venv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \"\"\"\n\u001b[1;32m    684\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m         \u001b[0;31m# TODO: treat KeyboardInterrupt as BaseException (delete the code below) in v1.7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_predict_impl\u001b[0;34m(self, model, dataloaders, datamodule, return_predictions, ckpt_path)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         )\n\u001b[1;32m   1036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicted_ckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_configure_sharded_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# allow user to setup in model sharded environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.8/site-packages/pytorch_lightning/accelerators/gpu.py\u001b[0m in \u001b[0;36msetup\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pl.Trainer\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_nvidia_flags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_rank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36msetup\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \"\"\"\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_training_type_plugin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_optimizers_in_pre_dispatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_optimizers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36msetup_training_type_plugin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msetup_training_type_plugin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0;34m\"\"\"Attaches the training type plugin to the accelerator.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msetup_precision_plugin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/single_device.py\u001b[0m in \u001b[0;36msetup\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/single_device.py\u001b[0m in \u001b[0;36mmodel_to_device\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmodel_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.8/site-packages/pytorch_lightning/core/mixins/device_dtype_mixin.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__update_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DeviceDtypeModuleMixin\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    905\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 907\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m     def register_backward_hook(\n",
      "\u001b[0;32m~/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    599\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    903\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    904\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 905\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "import time\n",
    "\n",
    "intcem.intervention_policy = ConstantMaskPolicy(\n",
    "    cbm=intcem,\n",
    "    mask=np.ones((len(concept_map),)),\n",
    "    concept_group_map=concept_map,\n",
    "    num_groups_intervened=len(concept_map),\n",
    "    group_based=True,\n",
    "    include_prior=False,\n",
    ")\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    logger=False,\n",
    ")\n",
    "test_batch_results = trainer.predict(\n",
    "    intcem,\n",
    "    test_dl,\n",
    ")\n",
    "\n",
    "intcem_c_preds = np.concatenate(\n",
    "    list(map(lambda x: x[0].detach().cpu().numpy(), test_batch_results)),\n",
    "    axis=0,\n",
    ")\n",
    "intcem_c_embs = np.concatenate(\n",
    "    list(map(lambda x: x[1].detach().cpu().numpy(), test_batch_results)),\n",
    "    axis=0,\n",
    ")\n",
    "intcem_y_preds = np.concatenate(\n",
    "    list(map(lambda x: x[2].detach().cpu().numpy(), test_batch_results)),\n",
    "    axis=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "class UnNormalize(object):\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
    "        Returns:\n",
    "            Tensor: Normalized image.\n",
    "        \"\"\"\n",
    "        return tensor * np.expand_dims(np.expand_dims(self.std, axis=-1), axis=-1) + np.expand_dims(\n",
    "            np.expand_dims(self.mean, axis=-1),\n",
    "            axis=-1\n",
    "        )\n",
    "    \n",
    "def show_bird_image(image, ax):\n",
    "    ax.grid(False)\n",
    "    ax.axis(False)\n",
    "    ax.imshow(np.transpose(\n",
    "        (UnNormalize(mean=[0.5, 0.5, 0.5], std=[2, 2, 2])(image) * 255).astype(np.int32),\n",
    "        axes=[1, 2, 0]\n",
    "    ))\n",
    "\n",
    "def show_closest_activation_examples(\n",
    "    x_test,\n",
    "    test_dl,\n",
    "    test_c_embs,\n",
    "    concept_semantics=None,\n",
    "    num_examples=5,\n",
    "    shown_neighs=5,\n",
    "    scale=1.5,\n",
    "    selected_concepts=None,\n",
    "    seed=None,\n",
    "):\n",
    "    np.random.seed(seed)\n",
    "    selected_concepts = selected_concepts or list(range(test_c_embs.shape[1]))\n",
    "    for selected_concept in selected_concepts:\n",
    "        if concept_semantics is not None:\n",
    "            print(\n",
    "                \"Selected concept at index\",\n",
    "                selected_concept,\n",
    "                \"with semantics\",\n",
    "                concept_semantics[selected_concept],\n",
    "            )\n",
    "\n",
    "        selected_inds = []\n",
    "        for i, (_, _, c_batch) in enumerate(test_dl):\n",
    "            for idx, c in enumerate(c_batch):\n",
    "                if c[selected_concept] == 1:\n",
    "                    selected_inds.append(i*c_batch.shape[0] + idx)\n",
    "        selected_inds = np.random.choice(selected_inds, size=num_examples, replace=False,)\n",
    "        fig, axs = plt.subplots(\n",
    "            num_examples,\n",
    "            shown_neighs + 2,\n",
    "            figsize=(scale*shown_neighs, scale*num_examples),\n",
    "        )\n",
    "        if concept_semantics is not None:\n",
    "            fig.suptitle(\n",
    "                f'Closest Embeddings for Concept {concept_semantics[selected_concept]}',\n",
    "                fontsize=15,\n",
    "            )\n",
    "        for i, example_idx in enumerate(selected_inds):\n",
    "            show_bird_image(x_test[example_idx, :, :, :], axs[i, 0])\n",
    "            if i == 0:\n",
    "                # Then add a title here\n",
    "                axs[i, 0].set_title(\"Sample\", fontsize=20)\n",
    "            # Let's add an empty image in between as a separator\n",
    "            axs[i, 1].grid(False)\n",
    "            axs[i, 1].axis(False)\n",
    "            nbrs = NearestNeighbors(n_neighbors=(shown_neighs + 1), algorithm='ball_tree').fit(\n",
    "                test_c_embs[:, selected_concept, :]\n",
    "            )\n",
    "            [distances], [nearest_indices] = nbrs.kneighbors(test_c_embs[example_idx:example_idx+1, selected_concept, :])\n",
    "            for j, sample_idx in enumerate(nearest_indices[1:], start=2):\n",
    "                show_bird_image(x_test[sample_idx, :, :, :], axs[i, j])\n",
    "                if (i == 0) and ((j - 2) == shown_neighs // 2):\n",
    "                    axs[i, j].set_title(\"Nearest Neighbors\", fontsize=20)\n",
    "        fig.tight_layout()\n",
    "        fig.subplots_adjust(\n",
    "            wspace=0,\n",
    "            hspace=0,\n",
    "        )\n",
    "        plt.show()\n",
    "\n",
    "def show_concept_clusters(\n",
    "    x_test,\n",
    "    test_c_embs,\n",
    "    test_c_sems,\n",
    "    max_d=50, #100\n",
    "    concept_semantics=None,\n",
    "    show_activated_only=True,\n",
    "    show_examples=True,\n",
    "    max_clusters=5,\n",
    "    shown_samples=5,\n",
    "    scale=1.5,\n",
    "    selected_concepts=None,\n",
    "    model_name=\"\",\n",
    "):\n",
    "    selected_concepts = selected_concepts or list(range(test_c_embs.shape[1]))\n",
    "    for selected_concept in selected_concepts:\n",
    "        if concept_semantics is not None:\n",
    "            print(\n",
    "                \"Selected concept at index\",\n",
    "                selected_concept,\n",
    "                \"with semantics\",\n",
    "                concept_semantics[selected_concept],\n",
    "            )\n",
    "        if show_activated_only:\n",
    "            selected_inds = np.arange(0, test_c_embs.shape[0])[\n",
    "                test_c_sems[:, selected_concept] > 0.5,\n",
    "            ].astype(np.int32)\n",
    "        else:\n",
    "            selected_inds = np.arange(0, test_c_embs.shape[0]).astype(np.int32)\n",
    "\n",
    "        selected_test_embs = test_c_embs[\n",
    "            selected_inds,\n",
    "            :,\n",
    "            :\n",
    "        ]\n",
    "\n",
    "        if show_examples:\n",
    "            print(\"Examples of selected test samples:\")\n",
    "            fig = plt.figure(figsize=(14, 6))\n",
    "            for i, idx in enumerate(selected_inds[:8]):\n",
    "                fig.add_subplot(1, 8, i + 1)\n",
    "                show_bird_image(x_test[idx, :, :, :], plt)\n",
    "            plt.show()\n",
    "\n",
    "        # selected_test_embs = test_c_embs\n",
    "        Z = linkage(selected_test_embs[:, selected_concept, :], 'ward')\n",
    "        clusters = fcluster(Z, max_d, criterion='distance')\n",
    "        cluster_types = np.unique(clusters)\n",
    "        print(\"Found\", len(cluster_types), \"clusters from\", clusters.shape[0], \"samples\")\n",
    "        cluster_map = [\n",
    "            [] for _ in range(len(cluster_types))\n",
    "        ]\n",
    "        for i, cluster_type in enumerate(clusters):\n",
    "            cluster_map[cluster_type - 1].append(i)\n",
    "\n",
    "        fig, axs = plt.subplots(\n",
    "            min(len(cluster_map), max_clusters),\n",
    "            shown_samples,\n",
    "            figsize=(scale*shown_samples, scale*min(max_clusters, len(cluster_map))),\n",
    "        )\n",
    "        if concept_semantics is not None:\n",
    "            fig.suptitle(\n",
    "                f'{model_name} Sample Concept Clusters for Concept {concept_semantics[selected_concept]}',\n",
    "                fontsize=15,\n",
    "            )\n",
    "        for row in axs:\n",
    "            for ax in row:\n",
    "                ax.grid(False)\n",
    "                ax.axis(False)\n",
    "\n",
    "        for cluster_id, samples in enumerate(cluster_map):\n",
    "            if cluster_id >= max_clusters:\n",
    "                break\n",
    "            real_shown_samples = min(shown_samples, len(samples))\n",
    "            centroid = np.expand_dims(\n",
    "                np.mean(selected_test_embs[samples, selected_concept, :], axis=0),\n",
    "                axis=0,\n",
    "            )\n",
    "            nbrs = NearestNeighbors(n_neighbors=real_shown_samples, algorithm='ball_tree').fit(\n",
    "                selected_test_embs[samples, selected_concept, :]\n",
    "            )\n",
    "            [distances], [nearest_indices] = nbrs.kneighbors(centroid)\n",
    "            for i, sample_idx in enumerate(nearest_indices):\n",
    "                real_idx = selected_inds[samples[sample_idx]]\n",
    "                show_bird_image(x_test[real_idx, :, :, :], axs[cluster_id, i])\n",
    "        fig.tight_layout()\n",
    "        fig.subplots_adjust(\n",
    "            wspace=0,\n",
    "            hspace=0.1,\n",
    "        )\n",
    "        plt.show()\n",
    "\n",
    "def show_inter_concept_similarity(\n",
    "    x_test,\n",
    "    test_c_embs,\n",
    "    test_c_sems,\n",
    "    concept_semantics=None,\n",
    "    show_activated_only=True,\n",
    "    selected_concepts=None,\n",
    "    normalize=True,\n",
    "    n_closest=5,\n",
    "    metric='cosine',\n",
    "    to_console=True,\n",
    "):\n",
    "    selected_concepts = selected_concepts or list(range(test_c_embs.shape[1]))\n",
    "\n",
    "    centroids = np.zeros((len(selected_concepts), test_c_embs.shape[-1]))\n",
    "    for i, concept_idx in enumerate(selected_concepts):\n",
    "        if show_activated_only:\n",
    "            selected_inds = np.arange(0, test_c_embs.shape[0])[\n",
    "                test_c_sems[:, concept_idx] > 0.5,\n",
    "            ].astype(np.int32)\n",
    "        else:\n",
    "            selected_inds = np.arange(0, test_c_embs.shape[0]).astype(np.int32)\n",
    "\n",
    "        selected_test_embs = test_c_embs[\n",
    "            selected_inds,\n",
    "            :,\n",
    "            :\n",
    "        ]\n",
    "        centroids[i, :] = np.mean(\n",
    "            selected_test_embs[:, concept_idx, :],\n",
    "            axis=0,\n",
    "        )\n",
    "    if normalize:\n",
    "        centroids = sklearn.preprocessing.normalize(centroids, axis=1)\n",
    "    nbrs = NearestNeighbors(\n",
    "        n_neighbors=n_closest + 1,\n",
    "        algorithm='auto',\n",
    "        metric=metric,\n",
    "    ).fit(centroids)\n",
    "    \n",
    "    result = []\n",
    "    for i, concept_idx in enumerate(selected_concepts):\n",
    "        [distances], [nearest_concepts] = nbrs.kneighbors(centroids[i:i+1, :])\n",
    "        concept_name = concept_idx\n",
    "        nearest_concepts_idx = nearest_concepts\n",
    "        if concept_semantics is not None:\n",
    "            concept_name = concept_semantics[concept_idx]\n",
    "            nearest_concepts = np.array(concept_semantics)[nearest_concepts]\n",
    "        \n",
    "        if to_console:\n",
    "            print(f\"Nearest concepts to concept {concept_name}:\")\n",
    "        partial_lst = []\n",
    "        for j, name, dist in zip(nearest_concepts_idx, nearest_concepts[1:], distances[1:]):\n",
    "            if to_console:\n",
    "                print(f\"\\t{name} (distance {dist})\")\n",
    "            partial_lst.append((j, dist))\n",
    "        result.append(partial_lst)\n",
    "        if to_console:\n",
    "            print()\n",
    "    return centroids, result\n",
    "\n",
    "def plot_concept_centroids(\n",
    "    x_test,\n",
    "    test_c_embs,\n",
    "    test_c_sems,\n",
    "    concept_semantics=None,\n",
    "    selected_concepts=None,\n",
    "    perplexity=50,\n",
    "    n_iter=1000,\n",
    "    figsize=(8, 6),\n",
    "    show_activated_only=True,\n",
    "    model_name=\"SplitEmb\",\n",
    "    annotation_size=5,\n",
    "    concept_colors=None,\n",
    "    dot_size=10,\n",
    "    half_emb=False,\n",
    "):\n",
    "    selected_concepts = selected_concepts or list(range(test_c_embs.shape[1]))\n",
    "    if half_emb:\n",
    "        centroids = np.zeros((len(selected_concepts), test_c_embs.shape[-1]//2))\n",
    "    else:\n",
    "        centroids = np.zeros((len(selected_concepts), test_c_embs.shape[-1]))\n",
    "    for i, concept_idx in enumerate(selected_concepts):\n",
    "        if show_activated_only:\n",
    "            selected_inds = np.arange(0, test_c_embs.shape[0])[\n",
    "                test_c_sems[:, concept_idx] > 0.5,\n",
    "            ].astype(np.int32)\n",
    "        else:\n",
    "            selected_inds = np.arange(0, test_c_embs.shape[0]).astype(np.int32)\n",
    "        \n",
    "        if half_emb:\n",
    "            selected_test_embs = test_c_embs[\n",
    "                selected_inds,\n",
    "                :,\n",
    "                :test_c_embs.shape[-1]//2\n",
    "            ]\n",
    "        else:\n",
    "            selected_test_embs = test_c_embs[\n",
    "                selected_inds,\n",
    "                :,\n",
    "                :\n",
    "            ]\n",
    "        centroids[i, :] = np.mean(\n",
    "            selected_test_embs[:, concept_idx, :],\n",
    "            axis=0,\n",
    "        )\n",
    "#     centroids = sklearn.preprocessing.normalize(centroids, axis=1)\n",
    "    tsne = TSNE(\n",
    "        n_components=2,\n",
    "        verbose=1,\n",
    "        perplexity=perplexity,\n",
    "        n_iter=n_iter,\n",
    "        init='pca',\n",
    "        learning_rate='auto',\n",
    "    )\n",
    "    tsne_results = tsne.fit_transform(centroids)\n",
    "    fig, ax = plt.subplots(\n",
    "        1,\n",
    "        1,\n",
    "        figsize=figsize,\n",
    "    )\n",
    "    ax.set_title(\n",
    "        f\"{model_name} Cluster Centroids\",\n",
    "        fontsize=15,\n",
    "    )\n",
    "    if concept_colors is None:\n",
    "        colors = []\n",
    "        marker = []\n",
    "        concept_semantics = concept_semantics or [\n",
    "            f'concept_{idx}' for idx in selected_concepts\n",
    "        ]\n",
    "        for i, concept_idx in enumerate(selected_concepts):\n",
    "            concept_name = concept_semantics[concept_idx]\n",
    "            if \"color\" in concept_name:\n",
    "                marker.append(\"o\")\n",
    "                color = concept_name[concept_name.find(\"::\") + 2:]\n",
    "                colors.append(color)\n",
    "            else:\n",
    "                colors.append(\"black\")\n",
    "                marker.append(\"x\")\n",
    "    else:\n",
    "        colors = list(np.array(concept_colors)[selected_concepts])\n",
    "        markers = [\"o\" for _ in selected_concepts]\n",
    "    for i, color in enumerate(colors):\n",
    "        if color == \"buff\":\n",
    "            color = \"palegoldenrod\" \n",
    "        elif color == \"multi-colored\":\n",
    "            color = \"palegreen\"\n",
    "        elif color == \"white\":\n",
    "            color = \"cyan\"\n",
    "        colors[i] = color\n",
    "    ax.scatter(\n",
    "        tsne_results[:, 0],\n",
    "        tsne_results[:, 1],\n",
    "        c=colors,\n",
    "        s=dot_size,\n",
    "        # TODO!!!!!!!\n",
    "#         marker=markers,\n",
    "    )\n",
    "   \n",
    "    for i, concept_idx in enumerate(selected_concepts):\n",
    "        concept_name = concept_semantics[concept_idx]\n",
    "        ax.annotate(\n",
    "            concept_semantics[concept_idx],\n",
    "            (tsne_results[i, 0], tsne_results[i, 1]),\n",
    "            fontsize=annotation_size,\n",
    "        )\n",
    "    ax.grid(False)\n",
    "    ax.axis(False)\n",
    "    fig.legend(fontsize=10) #, loc='center right')\n",
    "    plt.show()\n",
    "            \n",
    "def plot_tsne_embeddings(\n",
    "    test_c_embs,\n",
    "    c_test,\n",
    "    color_activations=None,\n",
    "    color_activation_labels=None,\n",
    "    attributes=None,\n",
    "    perplexity=50,\n",
    "    n_iter=1000,\n",
    "    figsize=(8, 6),\n",
    "    selected_concepts=None,\n",
    "    y_test=None,\n",
    "    model_name=\"SplitEmb\",\n",
    "):\n",
    "    results = []\n",
    "    selected_concepts = selected_concepts or list(range(test_c_embs.shape[1]))\n",
    "    for selected_concept in selected_concepts:\n",
    "        if attributes is not None:\n",
    "            print(\n",
    "                \"Selected concept at index\",\n",
    "                selected_concept,\n",
    "                \"with semantics\",\n",
    "                attributes[selected_concept],\n",
    "            )\n",
    "        tsne = TSNE(\n",
    "            n_components=2,\n",
    "            verbose=1,\n",
    "            perplexity=perplexity,\n",
    "            n_iter=n_iter,\n",
    "            init='pca',\n",
    "            learning_rate='auto',\n",
    "        )\n",
    "        tsne_results = tsne.fit_transform(test_c_embs[:, selected_concept, :])\n",
    "        results.append(tsne_results)\n",
    "        if y_test is not None:\n",
    "            fig, ax = plt.subplots(\n",
    "                1,\n",
    "                1,\n",
    "                figsize=figsize,\n",
    "            )\n",
    "            if attributes is not None:\n",
    "                ax.set_title(\n",
    "                    f\"TSNE Embeddings for {attributes[selected_concept]} (by class)\",\n",
    "                    fontsize=15,\n",
    "                )\n",
    "            ax.scatter(\n",
    "                tsne_results[:, 0],\n",
    "                tsne_results[:, 1],\n",
    "                c=y_test,\n",
    "                s=5,\n",
    "                cmap='ocean',\n",
    "            )\n",
    "            ax.grid(False)\n",
    "            ax.axis(False)\n",
    "            plt.show()\n",
    "            \n",
    "        if color_activations is not None:\n",
    "            activations = color_activations\n",
    "        else:\n",
    "            activations = [c_test[:, selected_concept]]\n",
    "        for i, activation in enumerate(activations):\n",
    "            if color_activation_labels is not None:\n",
    "                activation_label = color_activation_labels[i]\n",
    "            elif (color_activations is None):\n",
    "                if (attributes is not None):\n",
    "                    activation_label = attributes[selected_concept]\n",
    "                else:\n",
    "                    activation_label = f\"Concept {selected_concept + 1}\"\n",
    "            else:\n",
    "                activation_label = f\"Concept {i + 1}\"\n",
    "            \n",
    "            mask = activation == 1\n",
    "            neg_mask = np.logical_not(mask)\n",
    "\n",
    "            # And let's plot all of these\n",
    "            fig, ax = plt.subplots(\n",
    "                1,\n",
    "                1,\n",
    "                figsize=figsize,\n",
    "            )\n",
    "            if attributes is not None:\n",
    "                ax.set_title(\n",
    "                    f\"{model_name} TSNE Embeddings for {attributes[selected_concept]}\",\n",
    "                    fontsize=15,\n",
    "                )\n",
    "            ax.scatter(\n",
    "                tsne_results[mask, 0],\n",
    "                tsne_results[mask, 1],\n",
    "                color='red',\n",
    "                label=activation_label + \" active\",\n",
    "                s=5,\n",
    "            )\n",
    "\n",
    "            ax.scatter(\n",
    "                tsne_results[neg_mask, 0],\n",
    "                tsne_results[neg_mask, 1],\n",
    "                color='blue',\n",
    "                label=activation_label + \" not active\",\n",
    "                s=5,\n",
    "            )\n",
    "            ax.grid(False)\n",
    "            ax.axis(False)\n",
    "            fig.legend(fontsize=10) #, loc='center right')\n",
    "            plt.show()\n",
    "        \n",
    "    return results\n",
    "\n",
    "\n",
    "def plot_tsne_latent_space(\n",
    "    test_c_embs,\n",
    "    c_test,\n",
    "    attributes=None,\n",
    "    perplexity=50,\n",
    "    n_iter=1000,\n",
    "    figsize=(8, 6),\n",
    "    selected_concepts=None,\n",
    "    y_test=None,\n",
    "):\n",
    "    tsne = TSNE(\n",
    "        n_components=2,\n",
    "        verbose=1,\n",
    "        perplexity=perplexity,\n",
    "        n_iter=n_iter,\n",
    "        init='pca',\n",
    "        learning_rate='auto',\n",
    "    )\n",
    "    latent_space = test_c_embs.reshape(\n",
    "        test_c_embs.shape[0],\n",
    "        -1,\n",
    "    )\n",
    "    tsne_results = tsne.fit_transform(latent_space)\n",
    "    selected_concepts = selected_concepts or list(range(test_c_embs.shape[1]))\n",
    "    if y_test is not None:\n",
    "        fig, ax = plt.subplots(\n",
    "            1,\n",
    "            1,\n",
    "            figsize=figsize,\n",
    "        )\n",
    "        if attributes is not None:\n",
    "            ax.set_title(\n",
    "                f\"SplitEmb COMPLETE Latent Space TSNE colored by class\",\n",
    "                fontsize=15,\n",
    "            )\n",
    "        ax.scatter(\n",
    "            tsne_results[:, 0],\n",
    "            tsne_results[:, 1],\n",
    "            c=y_test,\n",
    "            s=5,\n",
    "            cmap='ocean',\n",
    "        )\n",
    "\n",
    "        ax.grid(False)\n",
    "        ax.axis(False)\n",
    "        plt.show()\n",
    "        \n",
    "    for selected_concept in selected_concepts:\n",
    "        if attributes is not None:\n",
    "            print(\n",
    "                \"Selected concept at index\",\n",
    "                selected_concept,\n",
    "                \"with semantics\",\n",
    "                attributes[selected_concept],\n",
    "            )\n",
    "\n",
    "        mask = c_test[:, selected_concept] == 1\n",
    "        neg_mask = np.logical_not(mask)\n",
    "\n",
    "        # And let's plot all of these\n",
    "        fig, ax = plt.subplots(\n",
    "            1,\n",
    "            1,\n",
    "            figsize=figsize,\n",
    "        )\n",
    "        if attributes is not None:\n",
    "            ax.set_title(\n",
    "                f\"SplitEmb COMPLETE Latent Space TSNE colored by {attributes[selected_concept]}\",\n",
    "                fontsize=15,\n",
    "            )\n",
    "        ax.scatter(\n",
    "            tsne_results[mask, 0],\n",
    "            tsne_results[mask, 1],\n",
    "            color='red',\n",
    "            label=\"Concept activated\",\n",
    "            s=5,\n",
    "        )\n",
    "\n",
    "        ax.scatter(\n",
    "            tsne_results[neg_mask, 0],\n",
    "            tsne_results[neg_mask, 1],\n",
    "            color='blue',\n",
    "            label=\"Concept not present\",\n",
    "            s=5,\n",
    "        )\n",
    "        ax.grid(False)\n",
    "        ax.axis(False)\n",
    "        fig.legend(fontsize=10) #, loc='center right')\n",
    "        plt.show()\n",
    "    return tsne_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main_kernel",
   "language": "python",
   "name": "main_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
